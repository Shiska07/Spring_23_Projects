{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Shiska Raut <br>\n",
    "ID: 1001526329"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read training/evaluation data\n",
    "\n",
    "**Argument(s):** name of a .txt file with each line containing training/evaluation features(x) and label(y) in the following format:\n",
    "((x1, x2, .....xn), y)  \n",
    "\n",
    "**Return(s):** 'X, Y' where X is a numpy array of feature vectors and Y is the target label vector.\n",
    "Note: Each column in the array(s) epresents a single datapoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a file\n",
    "def get_X_Y_arrays(filename):\n",
    "    try:\n",
    "        f = open(filename, 'r')\n",
    "    except OSError:\n",
    "        print(f'{filename} could not be opened.\\n')\n",
    "        sys.exit()\n",
    "        \n",
    "    # initialize list to store feature and labels for training data\n",
    "    features = []             \n",
    "    labels = []\n",
    "    \n",
    "    with f:\n",
    "        line = f.readline()\n",
    "        while line != '':\n",
    "            # strip newline and outer parenthesis\n",
    "            line = line.strip('\\n')\n",
    "            line = line.strip('( )')\n",
    "            \n",
    "            # extrace label and append to labels list\n",
    "            single_label = line.split('), ')[-1]\n",
    "            labels.append(single_label)\n",
    "            \n",
    "            # extrace features and append to features list\n",
    "            feat = line.split('), ')[0].split(', ')\n",
    "            features.append(feat)\n",
    "            \n",
    "            # read next line\n",
    "            line = f.readline()\n",
    "        \n",
    "        # create dataframe of features and append labels\n",
    "        X = np.array(features, dtype = float, ndmin = 2)\n",
    "        \n",
    "        # convert labels list to array\n",
    "        Y = np.array(labels, dtype = str, ndmin = 2)\n",
    "        \n",
    "        return X.transpose(), Y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read test data\n",
    "\n",
    "**Argument(s):** name of a .txt file with each line containing test features(x) in the following format:\n",
    "(x1, x2, .....xn)\n",
    "\n",
    "**Return(s):** 'X' where X is a numpy array of feature vectors.\n",
    "Note: Each column in the array(s) epresents a single datapoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_array(filename):\n",
    "    try:\n",
    "        f = open(filename, 'r')\n",
    "    except OSError:\n",
    "        print(f'{filename} could not be opened.\\n')\n",
    "        sys.exit()\n",
    "        \n",
    "    # initialize list to store feature and labels for training data\n",
    "    features = []             \n",
    "    \n",
    "    with f:\n",
    "        line = f.readline()\n",
    "        while line != '':\n",
    "            \n",
    "            # get feature values\n",
    "            line = line.strip('\\n')\n",
    "            line = line.strip('( )')\n",
    "            feat = line.split(', ')\n",
    "            features.append(feat)\n",
    "            \n",
    "            # read next line\n",
    "            line = f.readline()\n",
    "        \n",
    "        # create dataframe of features and append labels\n",
    "        X = np.array(features, dtype = float, ndmin = 2)\n",
    "        \n",
    "        return X.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = frequency increment\n",
    "# d = function depth\n",
    "# given input datapoint 'x_sample', \n",
    "# returns transformed version of the intput datapoint as a numpy array\n",
    "def get_feature_vector(x_sample, k, d):\n",
    "    \n",
    "    # stored transformed values in a list\n",
    "    trans_feat_list = []\n",
    "    \n",
    "    # append 1 and value of 'x_sample' to the list\n",
    "    trans_feat_list.append(float(1))\n",
    "    trans_feat_list.append(float(x_sample))\n",
    "    \n",
    "    # remaining transformations will be based on 'k' and 'd'\n",
    "    for i in range(1, d+1):\n",
    "        val1 = (np.sin(i*k*x_sample, dtype = float)**(i*k))*np.cos(x_sample, dtype = float)\n",
    "        trans_feat_list.append(val1)\n",
    "        val2 = (np.cos(i*k*x_sample, dtype = float)**(i*k))*np.sin(x_sample, dtype = float)\n",
    "        trans_feat_list.append(val2)\n",
    "    \n",
    "    return np.array(trans_feat_list, dtype = float, ndmin = 2).transpose()\n",
    "\n",
    "\n",
    "# calculates sample squared error\n",
    "def get_sample_squared_error(y_sample, y_pred):\n",
    "    \n",
    "    # calculate and return squared error\n",
    "    return np.square(y_sample - y_pred)\n",
    "\n",
    "\n",
    "# get's prediction value for a sample\n",
    "def get_prediction_value(x_sample, param_vec, k, d):\n",
    "    \n",
    "    # return prediction value\n",
    "    return np.dot(param_vec, get_feature_vector(x_sample, k, d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_vector(2, 1, 3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trains a linear regression model \n",
    "def train_model(X_train, Y_train, epochs, alpha, k, d):\n",
    "    \n",
    "    # get number of training samples\n",
    "    n_feat, n_samples = X_train.shape\n",
    "    \n",
    "    # get output dimension\n",
    "    n_out, __ = Y.train.shape\n",
    "    \n",
    "    # initialize parameter vector\n",
    "    param_vec = np.random.randn(n_out, d+2)\n",
    "    \n",
    "    # do this per epoch\n",
    "    for i in range(epochs):    \n",
    "        for j in range(n_samples):\n",
    "            \n",
    "            # pick a sample randomly\n",
    "            idx = np.random.randint(0, n_samples)\n",
    "            x_sample = X_train[idx]\n",
    "            y_sample = Y_train[idx]\n",
    "            \n",
    "            # get prediction value and adjust weights\n",
    "            y_pred = get_prediction_value(x_sample, param_vec, k, d)\n",
    "            gradient_vec = get_feature_vector(x_sample, k, g)*(y_pred - y_sample)\n",
    "            \n",
    "            # adjust parameter values using stochastic gradient descent\n",
    "            param_vec = param_vec - (alpha*gradient_vec)\n",
    "    \n",
    "    # return final parameter vector\n",
    "    return param_vec\n",
    "\n",
    "# returns predicted values and squared error given test data\n",
    "def get_prediction(X_test, Y_test, param_vec, k, d):\n",
    "    \n",
    "    # save number of test samples\n",
    "    n_feat, n_test_samples = X_test.shape\n",
    "    \n",
    "    # initialize list to store squared error and predictions\n",
    "    test_se = []\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(n_test_samples):\n",
    "        y_pred = get_prediction_value(X_test[i], params_vec, k, d)\n",
    "        predictions.append(y_pred)\n",
    "        sample_se = get_sample_squared_error(Y_test[i], y_pred)\n",
    "        test_se.append(sample_se)\n",
    "        \n",
    "    return predictions, test_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locally Weighted Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Softmax Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one_hot_encoder(arr) : return encoded_arr, label_idx_dict\n",
    "**arr:** <br>\n",
    "[['Ceramic' 'Metal' 'Metal' 'Metal' 'Ceramic' 'Plastic' 'Plastic'\n",
    "  'Plastic' 'Plastic' 'Plastic' 'Plastic' 'Ceramic']]<br>  \n",
    "**encoded_arr:** <br>\n",
    "[[0 1 1 1 0 0 0 0 0 0 0 0]<br>\n",
    " [0 0 0 0 0 1 1 1 1 1 1 0]<br>\n",
    " [1 0 0 0 1 0 0 0 0 0 0 1]] <br>\n",
    "**label_idx_dict:** <br>\n",
    "{'Metal': 0, 'Plastic': 1, 'Ceramic': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given an array of attribute values for a categocial attribute,\n",
    "# preforms one-hot-encoding and returns resulting binary array\n",
    "def one_hot_encoder(arr):\n",
    "    \n",
    "    __, n_samples = arr.shape\n",
    "    \n",
    "    # get unique labels\n",
    "    uniq_labels = set(arr[0,:].tolist())\n",
    "    \n",
    "    # get number of total attribute values\n",
    "    n_labels = len(uniq_labels)\n",
    "    \n",
    "    # create an array of size n_labels*n_samples to store encoded values\n",
    "    encoded_arr = np.zeros((n_labels, n_samples), dtype = int)\n",
    "    \n",
    "    # create dictionary to store row indev of each attribute value\n",
    "    label_idx_dict = {}\n",
    "    for i, v in enumerate(uniq_labels):\n",
    "        label_idx_dict[v] = i\n",
    "        \n",
    "    # fill encoded_arr using attribute index dictionary and input arr\n",
    "    for i in range(n_samples):\n",
    "        # get index to encode as 1\n",
    "        idx = label_idx_dict[arr[0,i]]\n",
    "        encoded_arr[idx, i] = 1\n",
    "        \n",
    "    return encoded_arr, label_idx_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reverse_encoder(arr_2D, label_idx_list) : return decoded_arr\n",
    "**arr_2D:** <br>\n",
    "[[0 1 1 1 0 0 0 0 0 0 0 0]<br>\n",
    " [0 0 0 0 0 1 1 1 1 1 1 0]<br>\n",
    " [1 0 0 0 1 0 0 0 0 0 0 1]] <br>\n",
    "**label_idx_dict:** <br>\n",
    "{'Metal': 0, 'Plastic': 1, 'Ceramic': 2} <br>\n",
    "**idx_arr:** <br>\n",
    "array([2, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 2]) <br>\n",
    "**decoded_arr:** <br> \n",
    "[['Ceramic' 'Metal' 'Metal' 'Metal' 'Ceramic' 'Plastic' 'Plastic'\n",
    "  'Plastic' 'Plastic' 'Plastic' 'Plastic' 'Ceramic']] <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given an array of one hot encoded values and a dictionary with 'original attribute': encoded index info\n",
    "# reverses the encoding and returns original attribute values\n",
    "def reverse_encoder(arr_2D, label_idx_dict):\n",
    "    \n",
    "    # get no of samples and atttribute values\n",
    "    n_labels, n_samples = arr_2D.shape\n",
    "    \n",
    "    # idx_arr gets and stores the index of the encoded '1' for each column/datapoint\n",
    "    idx_arr = arr_2D * np.arange(n_labels, dtype = int).reshape(n_attrib,1)\n",
    "    idx_arr = np.sum(idx_arr, axis = 0)\n",
    "    \n",
    "    # initialize list ot sore original labels\n",
    "    orig_labels = []\n",
    "    \n",
    "    # get inverse of the dictionary\n",
    "    inv_label_idx_dict = {v: k for k, v in label_idx_dict.items()}\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        orig_labels.append(inv_label_idx_dict[idx_arr[i]])\n",
    "    \n",
    "    # return original labels as an array\n",
    "    return np.array(orig_labels, dtype = str, ndmin = 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Training and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a vector of parobaility values, returns label with max probability for a single sample\n",
    "def get_sample_prediction_label(sfmax_net, label_idx_dict):\n",
    "    \n",
    "    # get inverse of the dictionary\n",
    "    inv_label_idx_dict = {v: k for k, v in label_idx_dict.items()}\n",
    "    \n",
    "    # return label with max probability value\n",
    "    return inv_label_idx_dict[np.argmax(sfmax_net, axis = 0)]\n",
    "\n",
    "\n",
    "# uses softmax function and parameter matrix to get probability values\n",
    "# for multiclass classification\n",
    "def get_sample_prediction_values(x, param_mtx):\n",
    "    \n",
    "    # initialize column vector of ones to add bias\n",
    "    x_sample = np.ones((x.shape[0]+1, 1), dtype = float)\n",
    "    x_sample[1::] = x.reshape(x.shape[0], 1)\n",
    "    \n",
    "    # calculate linear net value\n",
    "    net = np.dot(param_mtx, x_sample)\n",
    "    \n",
    "    # calculate exponential value for rach class\n",
    "    exp_net = np.exp(net)\n",
    "    \n",
    "    # calculate softmax value for each class\n",
    "    sfmax_net = exp_net/np.sum(exp_net, axis = 0)\n",
    "    \n",
    "    return sfmax_net\n",
    "\n",
    "\n",
    "# trains a softmax regression model given training data, alpha and number of epochs\n",
    "def train_softmax_regressor(X_train, Y_train, alpha, epochs):\n",
    "    \n",
    "    # get number of features and samples\n",
    "    n_feat, n_samples = X_train.shape\n",
    "    \n",
    "    # get encoded array for y\n",
    "    Y_train_encoded, label_idx_dict = one_hot_encoder(Y_train)\n",
    "    \n",
    "    # get no of classes/labels\n",
    "    n_class, __ = Y_train_encoded.shape\n",
    "    \n",
    "    # get paramater matrix\n",
    "    param_mtx = np.random.randn(n_class, n_feat+1)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        for j in range(n_samples):\n",
    "            \n",
    "            # pick a sample randomly\n",
    "            idx = np.random.randint(0, n_samples)\n",
    "            x_sample = X_train[:,idx]\n",
    "            y_sample = Y_train_encoded[:,idx].reshape(Y_train_encoded.shape[0], 1)\n",
    "            \n",
    "            # get prediction value and adjust weights\n",
    "            y_pred = get_sample_prediction_values(x_sample, param_mtx)\n",
    "            \n",
    "            # calculate gradient matrix\n",
    "            gradient_mtx = np.dot((y_sample - y_pred), x_sample.transpose())\n",
    "            \n",
    "            # adjust parameter values using stochastic gradient ascent\n",
    "            param_mtx = param_mtx + alpha*gradient_mtx\n",
    "            \n",
    "    # return final parameter matrix\n",
    "    return param_mtx, label_idx_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for leave-one-out-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out_evaluation(X_eval, Y_eval, alpha, epochs):\n",
    "    \n",
    "    # get number of features and samples\n",
    "    n_feat, n_samples = X_eval.shape\n",
    "    \n",
    "    # prediction labels generated by 'predict_class_with_knn' will be stored in this list\n",
    "    Y_pred = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        \n",
    "        # pick test datapoint\n",
    "        x_test = X_train[:,i]\n",
    "        y_test = Y_train[:,i]\n",
    "        \n",
    "        # create traiing set by deleting test datapoint\n",
    "        X_train = np.delete(X_eval, i, axis = 1)\n",
    "        Y_train = np.delete(Y_eval, i, axis = 1)\n",
    "        \n",
    "        # train model\n",
    "        model_params, label_idx_dict = train_softmax_regressor(X_train, Y_train, alpha, epochs)\n",
    "        \n",
    "        # get test data prediction\n",
    "        y_pred_values = get_sample_prediction_values(x_test, model_params)\n",
    "        y_pred_label = get_sample_prediction_label(y_pred_values, label_idx_list)\n",
    "        Y_pred.append(y_pred_label)\n",
    "    \n",
    "    # convert prediction list to numpy array\n",
    "    Y_pred = np.array(Y_pred, dtype = str, ndmin = 2)\n",
    "    \n",
    "    # return accuracy\n",
    "    return (np.sum(Y_eval == Y_pred))/n_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide Filenames:\n",
    "1) Training/evaluation file: name of a .txt file with each line containing training/evaluation features(x) and label(y) in the following format:\n",
    "((x1, x2, .....xn), y)\n",
    "\n",
    "2) Test file: name of a .txt file with each line containing test features(x) in the following format:\n",
    "(x1, x2, .....xn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "fname_train = str(input('Enter file containing training data: '))\n",
    "fname_test = str(input('Enter file containing test data: '))\n",
    "fname_eval = str(input('Enter file containing leave_one_out evaluation data: '))\n",
    "'''\n",
    "fname_train = '3_train.txt'\n",
    "fname_test = '3_test.txt'\n",
    "fname_eval = '3_eval.txt'\n",
    "\n",
    "X_train, Y_train = get_X_Y_arrays(fname_train)\n",
    "X_test = get_X_array(fname_test)\n",
    "X_eval, Y_eval = get_X_Y_arrays(fname_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Ceramic', 'Metal', 'Metal', 'Metal', 'Ceramic', 'Plastic',\n",
       "        'Plastic', 'Plastic', 'Plastic', 'Plastic', 'Plastic', 'Ceramic']],\n",
       "      dtype='<U7')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr, my_dict = one_hot_encoder(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Ceramic', 'Metal', 'Metal', 'Metal', 'Ceramic', 'Plastic',\n",
       "        'Plastic', 'Plastic', 'Plastic', 'Plastic', 'Plastic', 'Ceramic']],\n",
       "      dtype='<U7')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_encoder(arr, my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.array([[0.2],[1.5],[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14503605],\n",
       "       [0.53218029],\n",
       "       [0.32278366]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate exponential value for rach class\n",
    "exp_net = np.exp(np.array([[0.2],[1.5],[1]]))\n",
    "\n",
    "# calculate softmax value for each class\n",
    "exp_net/np.sum(exp_net, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((5+1, 1), dtype = float).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
