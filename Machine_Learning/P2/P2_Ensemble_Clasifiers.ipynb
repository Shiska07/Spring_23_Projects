{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Shiska Raut <br>\n",
    "ID: 1001526329"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read training/evaluation data\n",
    "\n",
    "**Argument(s):** \n",
    "1) filename: name of a .txt file with each line containing training/evaluation features(x) and label(y) in the following format:\n",
    "((x1, x2, .....xn), y) <br>\n",
    "2) dtype_x : datatype of features <br>\n",
    "3) dtype_y: datatype of label <br>\n",
    "\n",
    "**Return(s):** 'X, Y' where X is a numpy array of feature vectors and Y is the target label vector.\n",
    "Note: Each column in the array(s) epresents a single datapoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_Y_arrays(filename, dtype_x, dtype_y):\n",
    "    try:\n",
    "        f = open(filename, 'r')\n",
    "    except OSError:\n",
    "        print(f'{filename} could not be opened.\\n')\n",
    "        sys.exit()\n",
    "        \n",
    "    # initialize list to store feature and labels for training data\n",
    "    features = []             \n",
    "    labels = []\n",
    "    \n",
    "    with f:\n",
    "        line = f.readline()\n",
    "        while line != '':\n",
    "            # strip newline and outer parenthesis\n",
    "            line = line.strip('\\n')\n",
    "            line = line.strip('( )')\n",
    "            \n",
    "            # extrace label and append to labels list\n",
    "            single_label = line.split('), ')[-1]\n",
    "            labels.append(single_label)\n",
    "            \n",
    "            # extrace features and append to features list\n",
    "            feat = line.split('), ')[0].split(', ')\n",
    "            features.append(feat)\n",
    "            \n",
    "            # read next line\n",
    "            line = f.readline()\n",
    "        \n",
    "        # create dataframe of features and append labels\n",
    "        X = np.array(features, dtype = dtype_x, ndmin = 2)\n",
    "        \n",
    "        # convert labels list to array\n",
    "        Y = np.array(labels, dtype = dtype_y, ndmin = 2)\n",
    "        \n",
    "        return X.transpose(), Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one_hot_encoder(arr) : return encoded_arr, label_idx_dict\n",
    "**arr:** <br>\n",
    "[['Ceramic' 'Metal' 'Metal' 'Metal' 'Ceramic' 'Plastic' 'Plastic'\n",
    "  'Plastic' 'Plastic' 'Plastic' 'Plastic' 'Ceramic']]<br>  \n",
    "**encoded_arr:** <br>\n",
    "[[0 1 1 1 0 0 0 0 0 0 0 0]<br>\n",
    " [0 0 0 0 0 1 1 1 1 1 1 0]<br>\n",
    " [1 0 0 0 1 0 0 0 0 0 0 1]] <br>\n",
    "**encoding_dict:** <br>\n",
    "{'Metal': 0, 'Plastic': 1, 'Ceramic': 2}<br>\n",
    "**decoding_dict:** <br>\n",
    "{0:'Metal', 1:'Plastic', 2:'Ceramic'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given an array of attribute values for a categocial attribute,\n",
    "# preforms one-hot-encoding and returns resulting binary array\n",
    "def one_hot_encoder(arr):\n",
    "    __, n_samples = arr.shape\n",
    "\n",
    "    # get unique labels\n",
    "    uniq_labels = set(arr[0, :].tolist())\n",
    "\n",
    "    # get number of total attribute values\n",
    "    n_labels = len(uniq_labels)\n",
    "\n",
    "    # create an array of size n_labels*n_samples to store encoded values\n",
    "    encoded_arr = np.zeros((n_labels, n_samples), dtype=int)\n",
    "\n",
    "    # create dictionary to store row indev of each attribute value\n",
    "    encoding_dict = {}\n",
    "    for i, v in enumerate(uniq_labels):\n",
    "        encoding_dict[v] = i\n",
    "\n",
    "    # fill encoded_arr using attribute index dictionary and input arr\n",
    "    for i in range(n_samples):\n",
    "        # get index to encode as 1\n",
    "        idx = encoding_dict[arr[0, i]]\n",
    "        encoded_arr[idx, i] = 1\n",
    "\n",
    "    # get inverse of the dictionary\n",
    "    decoding_dict = {v: k for k, v in encoding_dict.items()}\n",
    "\n",
    "    return encoded_arr, encoding_dict, decoding_dict\n",
    "\n",
    "\n",
    "# given a one-hot encoded array and a decoding_dict returns decoded array\n",
    "def get_decoded_arr(arr, decoding_dict):\n",
    "\n",
    "    # get number of samples\n",
    "    n_samples = arr.shape[1]\n",
    "\n",
    "    arr_decoded = np.zeros((1, n_samples), dtype = object)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        arr_decoded[:, i] = decoding_dict[np.argmax(arr[:, i])]\n",
    "\n",
    "    return arr_decoded\n",
    "\n",
    "\n",
    "# given an array of labels and encoding dict returns encoded array\n",
    "def get_encoded_arr(arr, encoding_dict):\n",
    "\n",
    "    # get number of classes and number of samples\n",
    "    n_class = len(encoding_dict.keys())\n",
    "    n_samples = arr.shape[1]\n",
    "\n",
    "    encoded_arr = np.zeros((n_class, n_samples), dtype = int)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "\n",
    "        idx = encoding_dict[arr[:, i][0]]\n",
    "        encoded_arr[idx, i] = int(1)\n",
    "\n",
    "    return encoded_arr\n",
    "\n",
    "# adds bias as the first row to a dataset\n",
    "def add_bias(X):\n",
    "    \n",
    "    n_feat, n_samples = X.shape\n",
    "    X_b = np.ones((n_feat+1, n_samples), dtype = float)\n",
    "    X_b[1::,:] = X\n",
    "    \n",
    "    return X_b\n",
    "\n",
    "\n",
    "# plots a line graph \n",
    "def plot_change(X, title, xlab, ylab):\n",
    "    \n",
    "    fig = plt.figure(figsize = (10, 6))\n",
    "    plt.plot(X, color = 'red')\n",
    "    \n",
    "    # add title and labels\n",
    "    plt.title(title, fontdict = {'fontsize': 15})\n",
    "    plt.xlabel(xlab, fontdict = {'fontsize': 12})\n",
    "    plt.ylabel(ylab, fontdict = {'fontsize': 12})\n",
    "    plt.grid()\n",
    "\n",
    "    \n",
    "# compares two arrays and returns class accuracy\n",
    "# Y_pred.shape == Y.shape = ndim, n_samples \n",
    "# Y_pred.dtype = Y.dtype + string object\n",
    "def get_class_acc(Y_pred, Y):\n",
    "    \n",
    "    # create a dict to store class accuracy\n",
    "    class_acc = {}\n",
    "    \n",
    "    # get all unique classes\n",
    "    classes = set(Y[0,:].tolist())\n",
    "    \n",
    "    # get number of samples\n",
    "    n_samples = Y_pred.shape[1]\n",
    "    \n",
    "    # calculate total occurence and accurate predictions for each class\n",
    "    for c in classes:\n",
    "        \n",
    "        total = 0\n",
    "        acc_vals = 0\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            if Y[:,i] == c:\n",
    "                total = total + 1\n",
    "                if Y[:,i] == Y_pred[:,i]:\n",
    "                    acc_vals = acc_vals + 1\n",
    "                \n",
    "        class_acc[c] = acc_vals/total\n",
    "        \n",
    "    return class_acc\n",
    "\n",
    "\n",
    "# compares two arrays and returns overall accuracy\n",
    "# Y_pred.shape == Y.shape = ndim, n_samples \n",
    "# Y_pred.dtype = Y.dtype + string object\n",
    "def get_acc(Y_pred, Y):\n",
    "    \n",
    "    n_samples = Y_pred.shape[1]\n",
    "    \n",
    "    # reutrn overall accuracy\n",
    "    return (np.sum(Y == Y_pred))/n_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Training and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a vector of parobaility values, returns label with max probability for a single sample\n",
    "def get_sample_prediction_label(sfmax_net, decoding_dict):\n",
    "    \n",
    "    # return label with max probability value\n",
    "    return decoding_dict[int(np.argmax(sfmax_net, axis = 0))]\n",
    "\n",
    "\n",
    "# uses softmax function and parameter matrix to get probability values\n",
    "# for multiclass classification\n",
    "def get_sample_prediction_values(x_sample, model_params):\n",
    "    \n",
    "    # calculate linear net value\n",
    "    net = np.dot(model_params, x_sample)\n",
    "    \n",
    "    # calculate exponential value for rach class\n",
    "    exp_net = np.exp(net, dtype = float)\n",
    "    \n",
    "    # calculate softmax value for each class\n",
    "    sfmax_net = exp_net/np.sum(exp_net, axis = 0, dtype = float)\n",
    "    \n",
    "    return sfmax_net\n",
    "\n",
    "\n",
    "# gets predictions for an entire test dataset\n",
    "def get_predictions(X_test, model_params, label_idx_dict):\n",
    "\n",
    "    # initialize list to store predictions\n",
    "    Y_pred = []\n",
    "\n",
    "    # get number of test samples\n",
    "    n_feat, n_samples = X_test.shape\n",
    "\n",
    "    for i in range(n_samples):\n",
    "    \n",
    "        x_sample = X_test[:,i].reshape(n_feat, 1)\n",
    "        y_pred_values = get_sample_prediction_values(X_test[:,i], model_params)\n",
    "        y_pred_label = get_sample_prediction_label(y_pred_values, label_idx_dict)\n",
    "        Y_pred.append(y_pred_label)\n",
    "\n",
    "    # convert labels list to numpy array\n",
    "    Y_pred = np.array(Y_pred, dtype = str, ndmin = 2)\n",
    "\n",
    "    return Y_pred  \n",
    "\n",
    "\n",
    "# training with batch gradient descent\n",
    "def train_softmax_regressor_batch(X_train, Y_train, alpha, epochs):\n",
    "    \n",
    "    # get number of features and samples\n",
    "    n_feat, n_samples = X_train.shape\n",
    "    \n",
    "    # get no of classes/labels\n",
    "    n_class, __ = Y_train.shape\n",
    "\n",
    "    # get paramater matrix\n",
    "    model_params = np.random.uniform(-0.01, 0.01, size = (n_class, n_feat))\n",
    "\n",
    "    # initialize list to store net change in parameter values\n",
    "    epoch_change_model_params = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "\n",
    "        # initialize gradient vector for each epoch\n",
    "        gradient_mtx = np.zeros((n_class, n_feat), dtype = float)\n",
    "\n",
    "        for j in range(n_samples):\n",
    "            \n",
    "            # pick a sample \n",
    "            x_sample = X_train[:,j].reshape(n_feat,1)\n",
    "            y_sample = Y_train[:,j].reshape(n_class, 1)\n",
    "            \n",
    "            # get prediction value\n",
    "            y_pred = get_sample_prediction_values(x_sample, model_params)\n",
    "\n",
    "            # calculate gradient matrix\n",
    "            sample_gradient = np.dot((y_sample - y_pred), x_sample.transpose())\n",
    "            gradient_mtx = gradient_mtx + sample_gradient\n",
    "            \n",
    "        # adjust parameter values using batch gradient descent \n",
    "        updated_params = model_params + (alpha*gradient_mtx)\n",
    "        \n",
    "        # get the net change in parameters\n",
    "        net_change = np.sum(np.abs(model_params - updated_params))\n",
    "        epoch_change_model_params.append(net_change)\n",
    "            \n",
    "        # set updated parameters as new parameters  \n",
    "        model_params = updated_params.copy()\n",
    "        \n",
    "    # return final parameter matrix\n",
    "    return model_params, epoch_change_model_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide Filename:\n",
    "1) Training/evaluation file: name of a .txt file with each line containing training/evaluation features(x) and label(y) in the following format:\n",
    "((x1, x2, .....xn), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'data.txt'\n",
    "\n",
    "X, Y = get_X_Y_arrays(fname, float, str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot class distribution of training data provided in assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (6, 4))\n",
    "plt.title(f'Class label distribution for \"{fname}\"')\n",
    "plt.ylabel('No. of datapoints')\n",
    "plt.hist(Y.squeeze())\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add bias to X training data\n",
    "X_b = add_bias(X)\n",
    "\n",
    "# get encoded values for Y_train\n",
    "Y_encoded, encoding_dict, decoding_dict = one_hot_encoder(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, Y, n_test_samples):\n",
    "\n",
    "    X_test = X[:, 0:n_test_samples]\n",
    "    Y_test = Y[:, 0:n_test_samples]\n",
    "\n",
    "    X_train = np.delete(X, np.s_[0:n_test_samples], axis = 1)\n",
    "    Y_train = np.delete(Y, np.s_[0:n_test_samples], axis = 1)\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and test set\n",
    "X_train, Y_train, X_test, Y_test = split_data(X_b, Y_encoded, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) a\n",
    "### Bagging Rautine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a list of 'n' dataset arrays created via random sampling with replacement \n",
    "def get_bootstrapped_datasets(X, Y, n):\n",
    "    \n",
    "    # initialze list to store datasets\n",
    "    X_list = []\n",
    "    Y_list = []\n",
    "    \n",
    "    # get number of samples\n",
    "    n_samples = X.shape[1]\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        # create array of same size as the original dataset\n",
    "        X_new = np.zeros((X.shape))\n",
    "        Y_new = np.zeros((Y.shape))\n",
    "        \n",
    "        for j in range(n_samples):\n",
    "            \n",
    "            # randomply pick an index\n",
    "            idx = np.random.randint(0, n_samples)\n",
    "            \n",
    "            X_new[:, j] = X[:, idx]\n",
    "            Y_new[:, j] = Y[:, idx]\n",
    "            \n",
    "        X_list.append(X_new)\n",
    "        Y_list.append(Y_new)\n",
    "    \n",
    "    return X_list, Y_list\n",
    "\n",
    "\n",
    "# trains n_classifiers on bootstrapped training data and returns model paramaters\n",
    "# and training accuracy values\n",
    "def train_classifiers(X_train, Y_train, n_classifiers, epochs, alpha, decoding_dict):\n",
    "    \n",
    "    # create datasets\n",
    "    datasets_X, datasets_Y = get_bootstrapped_datasets(X_train, Y_train, n_classifiers)\n",
    "    \n",
    "    # create list to store model_parameters and training accuracy\n",
    "    model_params_list = []\n",
    "    training_acc_list = []\n",
    "    \n",
    "    for i in range(n_classifiers):\n",
    "        \n",
    "        # train model and get predictions\n",
    "        model_params, __ = train_softmax_regressor_batch(datasets_X[i], datasets_Y[i], alpha, epochs)\n",
    "        \n",
    "        # get prediction on training data\n",
    "        Y_train_pred = get_predictions(datasets_X[i], model_params, decoding_dict)\n",
    "        \n",
    "        # decode labels\n",
    "        Y_train_labels = get_decoded_arr(datasets_Y[i], decoding_dict)\n",
    "        \n",
    "        # append model parameters\n",
    "        model_params_lista.append(model_params)\n",
    "        training_acc_list.append(get_acc(Y_train_pred, Y_train_labels))\n",
    "        \n",
    "    # return parameters for all models and training accuracy values\n",
    "    return model_params_list, training_acc_list\n",
    "\n",
    "\n",
    "# returns final prediction based on n_classifiers\n",
    "# and overall test accuracy\n",
    "def get_ensemble_prediction(X_test, model_params_list, n_classifiers):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 b)\n",
    "###  Single Classifier\n",
    "\n",
    "Train single softmax regression classifier on the original train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set epochs and alpha\n",
    "epochs = 1000\n",
    "alpha = 0.001\n",
    "\n",
    "# train model and get predictions\n",
    "model_params, epoch_change_model_params = train_softmax_regressor_batch(X_train, Y_train, alpha, epochs)\n",
    "\n",
    "Y_train_pred = get_predictions(X_train, model_params, decoding_dict)\n",
    "Y_test_pred = get_predictions(X_test, model_params, decoding_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get accuracy values for single classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Training accuracy is 0.438.\n",
      "Overall Test accuracy is 0.667.\n"
     ]
    }
   ],
   "source": [
    "# get decoded arrays for Y_train and Y_test\n",
    "Y_train_labels = get_decoded_arr(Y_train, decoding_dict)\n",
    "Y_test_labels = get_decoded_arr(Y_test, decoding_dict)\n",
    "\n",
    "# get accuracy for training and test data\n",
    "train_acc = get_acc(Y_train_pred, Y_train_labels)\n",
    "test_acc = get_acc(Y_test_pred, Y_test_labels)\n",
    "print(f'Overall Training accuracy is {train_acc:.3f}.')\n",
    "print(f'Overall Test accuracy is {test_acc:.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training class accuracy is:\n",
      "Ceramic: 0.000\n",
      "Metal: 0.115\n",
      "Plastic: 0.935\n",
      "\n",
      "Test class accuracy is:\n",
      "Ceramic: 0.000\n",
      "Metal: 0.429\n",
      "Plastic: 1.000\n"
     ]
    }
   ],
   "source": [
    "train_class_acc = get_class_acc(Y_train_pred, Y_train_labels)\n",
    "test_class_acc = get_class_acc(Y_test_pred, Y_test_labels)\n",
    "\n",
    "print(f'Training class accuracy is:')\n",
    "for k, v in train_class_acc.items():\n",
    "    print(f'{k}: {v:0.3f}')\n",
    "    \n",
    "print(f'\\nTest class accuracy is:')\n",
    "for k, v in test_class_acc.items():\n",
    "    print(f'{k}: {v:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging with 10, 50, 100 classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_X, datasets_Y = get_bootstrapped_datasets(X_train, Y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list to store all predictions on test data\n",
    "# for each classifier\n",
    "test_predictions = []\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
